{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Editor: @Hyunhomo\n",
    "Source: https://github.com/ashishpatel26/Predictive_Maintenance_using_Machine-Learning_Microsoft_Casestudy\n",
    "\n",
    "Load and assign data to pandas dataframe from CSV files\n",
    "'''\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Display setting\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "### Data assignment\n",
    "# read csv file and assign data into pandas DataFrame\n",
    "telemetry = pd.read_csv('PdM_ML/data/PdM_telemetry.csv')\n",
    "errors = pd.read_csv('PdM_ML/data/PdM_errors.csv')\n",
    "maint = pd.read_csv('PdM_ML/data/PdM_maint.csv')\n",
    "failures = pd.read_csv('PdM_ML/data/PdM_failures.csv')\n",
    "machines = pd.read_csv('PdM_ML/data/PdM_machines.csv')\n",
    "\n",
    "# format and type setting\n",
    "telemetry['datetime'] = pd.to_datetime(telemetry['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "errors['datetime'] = pd.to_datetime(errors['datetime'],format = '%Y-%m-%d %H:%M:%S')\n",
    "maint['datetime'] = pd.to_datetime(maint['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "failures['datetime'] = pd.to_datetime(failures['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "errors['errorID'] = errors['errorID'].astype('category')\n",
    "maint['comp'] = maint['comp'].astype('category')\n",
    "machines['model'] = machines['model'].astype('category')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).mean()\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).std()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).first()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).first()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:822: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:71: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  machineID        volt      rotate    pressure  \\\n",
      "0 2015-01-01 06:00:00          1  176.217853  418.504078  113.077935   \n",
      "1 2015-01-01 07:00:00          1  162.879223  402.747490   95.460525   \n",
      "2 2015-01-01 08:00:00          1  170.989902  527.349825   75.237905   \n",
      "3 2015-01-01 09:00:00          1  162.462833  346.149335  109.248561   \n",
      "4 2015-01-01 10:00:00          1  157.610021  435.376873  111.886648   \n",
      "\n",
      "   vibration  \n",
      "0  45.087686  \n",
      "1  43.413973  \n",
      "2  34.178847  \n",
      "3  41.122144  \n",
      "4  25.990511  \n",
      "    machineID            datetime  voltmean_3h  rotatemean_3h  \\\n",
      "7           1 2015-01-02 06:00:00   180.133784     440.608320   \n",
      "8           1 2015-01-02 09:00:00   176.364293     439.349655   \n",
      "9           1 2015-01-02 12:00:00   160.384568     424.385316   \n",
      "10          1 2015-01-02 15:00:00   170.472461     442.933997   \n",
      "11          1 2015-01-02 18:00:00   163.263806     468.937558   \n",
      "\n",
      "    pressuremean_3h  vibrationmean_3h  voltsd_3h  rotatesd_3h  pressuresd_3h  \\\n",
      "7         94.137969         41.551544  21.322735    48.770512       2.135684   \n",
      "8        101.553209         36.105580  18.952210    51.329636      13.789279   \n",
      "9         99.598722         36.094637  13.047080    13.702496       9.988609   \n",
      "10       102.380586         40.483002  16.642354    56.290447       3.305739   \n",
      "11       102.726648         40.921802  17.424688    38.680380       9.105775   \n",
      "\n",
      "    vibrationsd_3h  voltmean_24h  rotatemean_24h  pressuremean_24h  \\\n",
      "7        10.037208    169.733809      445.179865         96.797113   \n",
      "8         6.737739    170.614862      446.364859         96.849785   \n",
      "9         1.639962    169.893965      447.009407         97.715600   \n",
      "10        8.854145    171.243444      444.233563         96.666060   \n",
      "11        3.060781    170.792486      448.440437         95.766838   \n",
      "\n",
      "    vibrationmean_24h  voltsd_24h  rotatesd_24h  pressuresd_24h  \\\n",
      "7           40.385160  169.772951    447.502464       99.005946   \n",
      "8           39.736826  170.900562    453.864597      100.877342   \n",
      "9           39.498374  169.533156    454.785072      100.050567   \n",
      "10          40.229370  170.866013    463.871291       99.360632   \n",
      "11          40.055214  171.041651    463.701291       98.965877   \n",
      "\n",
      "    vibrationsd_24h  \n",
      "7         39.389725  \n",
      "8         38.696225  \n",
      "9         39.449734  \n",
      "10        40.766639  \n",
      "11        42.396850  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "Require bringing the different data sources together to create features \n",
    "that best describe a machines's health condition at a given point in time\n",
    "\n",
    "Lag Feature & Rolling Window Statistics\n",
    "'''\n",
    "\n",
    "## Calculate mean/std values for telemetry features\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "# for all the telemetry, resample every 3hours and calculate mean\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right', how='mean').unstack())\n",
    "telemetry_mean_3h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_3h.columns = [i + 'mean_3h' for i in fields]\n",
    "telemetry_mean_3h.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# repeat for standard deviation\n",
    "temp = []\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry,\n",
    "                               index='datetime',\n",
    "                               columns='machineID',\n",
    "                               values=col).resample('3H', closed='left', label='right', how='std').unstack())\n",
    "telemetry_sd_3h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_3h.columns = [i + 'sd_3h' for i in fields]\n",
    "telemetry_sd_3h.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# rolling every 8 of 3H data for capturing a longer term(24h) effect\n",
    "\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry,      index='datetime',\n",
    "                                               columns='machineID',\n",
    "                                               values=col).rolling(window=24,center=False).mean().resample('3H',\n",
    "                                                                                closed='left',\n",
    "                                                                                label='right',\n",
    "                                                                                how='first').unstack())\n",
    "telemetry_mean_24h = pd.concat(temp, axis=1)\n",
    "telemetry_mean_24h.columns = [i + 'mean_24h' for i in fields]\n",
    "telemetry_mean_24h.reset_index(inplace=True)\n",
    "telemetry_mean_24h = telemetry_mean_24h.loc[-telemetry_mean_24h['voltmean_24h'].isnull()]\n",
    "\n",
    "# repeat for standard deviation\n",
    "temp = []\n",
    "fields = ['volt', 'rotate', 'pressure', 'vibration']\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(telemetry, index='datetime',\n",
    "                                          columns='machineID',\n",
    "                                          values=col).rolling(window=24,center=False).mean().resample('3H',\n",
    "                                                                                closed='left',\n",
    "                                                                                label='right',\n",
    "                                                                                how='first').unstack())\n",
    "telemetry_sd_24h = pd.concat(temp, axis=1)\n",
    "telemetry_sd_24h.columns = [i + 'sd_24h' for i in fields]\n",
    "telemetry_sd_24h = telemetry_sd_24h.loc[-telemetry_sd_24h['voltsd_24h'].isnull()]\n",
    "telemetry_sd_24h.reset_index(inplace=True)\n",
    "\n",
    "# Notice that a 24h rolling average is not available at the earliest timepoints\n",
    "# print (telemetry_mean_24h.head(10))\n",
    "\n",
    "# merge columns of feature sets created earlier\n",
    "telemetry_feat = pd.concat([telemetry_mean_3h,\n",
    "                            telemetry_sd_3h.ix[:, 2:6],\n",
    "                            telemetry_mean_24h.ix[:, 2:6],\n",
    "                            telemetry_sd_24h.ix[:, 2:6]], axis=1).dropna()\n",
    "\n",
    "\n",
    "print(telemetry.head())\n",
    "print(telemetry_feat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  machineID errorID\n",
      "0 2015-01-03 07:00:00          1  error1\n",
      "1 2015-01-03 20:00:00          1  error3\n",
      "2 2015-01-04 06:00:00          1  error5\n",
      "3 2015-01-10 15:00:00          1  error4\n",
      "4 2015-01-22 10:00:00          1  error4\n",
      "   machineID            datetime  error1  error2  error3  error4  error5\n",
      "0          1 2015-01-03 07:00:00       1       0       0       0       0\n",
      "1          1 2015-01-03 20:00:00       0       0       1       0       0\n",
      "2          1 2015-01-04 06:00:00       0       0       0       0       1\n",
      "3          1 2015-01-10 15:00:00       0       0       0       1       0\n",
      "4          1 2015-01-22 10:00:00       0       0       0       1       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...).first()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    machineID            datetime  error1count  error2count  error3count  \\\n",
      "7           1 2015-01-02 06:00:00          0.0          0.0          0.0   \n",
      "8           1 2015-01-02 09:00:00          0.0          0.0          0.0   \n",
      "9           1 2015-01-02 12:00:00          0.0          0.0          0.0   \n",
      "10          1 2015-01-02 15:00:00          0.0          0.0          0.0   \n",
      "11          1 2015-01-02 18:00:00          0.0          0.0          0.0   \n",
      "12          1 2015-01-02 21:00:00          0.0          0.0          0.0   \n",
      "13          1 2015-01-03 00:00:00          0.0          0.0          0.0   \n",
      "14          1 2015-01-03 03:00:00          0.0          0.0          0.0   \n",
      "15          1 2015-01-03 06:00:00          0.0          0.0          0.0   \n",
      "16          1 2015-01-03 09:00:00          0.0          0.0          0.0   \n",
      "17          1 2015-01-03 12:00:00          1.0          0.0          0.0   \n",
      "18          1 2015-01-03 15:00:00          1.0          0.0          0.0   \n",
      "19          1 2015-01-03 18:00:00          1.0          0.0          0.0   \n",
      "20          1 2015-01-03 21:00:00          1.0          0.0          0.0   \n",
      "21          1 2015-01-04 00:00:00          1.0          0.0          1.0   \n",
      "22          1 2015-01-04 03:00:00          1.0          0.0          1.0   \n",
      "23          1 2015-01-04 06:00:00          1.0          0.0          1.0   \n",
      "24          1 2015-01-04 09:00:00          1.0          0.0          1.0   \n",
      "25          1 2015-01-04 12:00:00          0.0          0.0          1.0   \n",
      "26          1 2015-01-04 15:00:00          0.0          0.0          1.0   \n",
      "27          1 2015-01-04 18:00:00          0.0          0.0          1.0   \n",
      "28          1 2015-01-04 21:00:00          0.0          0.0          1.0   \n",
      "29          1 2015-01-05 00:00:00          0.0          0.0          0.0   \n",
      "30          1 2015-01-05 03:00:00          0.0          0.0          0.0   \n",
      "31          1 2015-01-05 06:00:00          0.0          0.0          0.0   \n",
      "32          1 2015-01-05 09:00:00          0.0          0.0          0.0   \n",
      "33          1 2015-01-05 12:00:00          0.0          0.0          0.0   \n",
      "34          1 2015-01-05 15:00:00          0.0          0.0          0.0   \n",
      "35          1 2015-01-05 18:00:00          0.0          0.0          0.0   \n",
      "36          1 2015-01-05 21:00:00          0.0          0.0          0.0   \n",
      "\n",
      "    error4count  error5count  \n",
      "7           0.0          0.0  \n",
      "8           0.0          0.0  \n",
      "9           0.0          0.0  \n",
      "10          0.0          0.0  \n",
      "11          0.0          0.0  \n",
      "12          0.0          0.0  \n",
      "13          0.0          0.0  \n",
      "14          0.0          0.0  \n",
      "15          0.0          0.0  \n",
      "16          0.0          0.0  \n",
      "17          0.0          0.0  \n",
      "18          0.0          0.0  \n",
      "19          0.0          0.0  \n",
      "20          0.0          0.0  \n",
      "21          0.0          0.0  \n",
      "22          0.0          0.0  \n",
      "23          0.0          0.0  \n",
      "24          0.0          1.0  \n",
      "25          0.0          1.0  \n",
      "26          0.0          1.0  \n",
      "27          0.0          1.0  \n",
      "28          0.0          1.0  \n",
      "29          0.0          1.0  \n",
      "30          0.0          1.0  \n",
      "31          0.0          1.0  \n",
      "32          0.0          0.0  \n",
      "33          0.0          0.0  \n",
      "34          0.0          0.0  \n",
      "35          0.0          0.0  \n",
      "36          0.0          0.0  \n"
     ]
    }
   ],
   "source": [
    "## Feature extraction from errors data (error IDs are categorical values\n",
    "# and should not be averaged over time intervals like the telemetry measurements)\n",
    "\n",
    "# create a column for each error type\n",
    "error_count = pd.get_dummies(errors.set_index('datetime')).reset_index()\n",
    "error_count\n",
    "error_count.columns = ['datetime', 'machineID', 'error1', 'error2', 'error3', 'error4', 'error5']\n",
    "# combine errors for a given machine in a given hour\n",
    "error_count = error_count.groupby(['machineID','datetime']).sum().reset_index()\n",
    "print(errors.head())\n",
    "print(error_count.head(5))\n",
    "\n",
    "error_count = telemetry[['datetime', 'machineID']].merge(error_count, on=['machineID', 'datetime'], how='left').fillna(0.0)\n",
    "\n",
    "\n",
    "#compute the total number of errors of each type over the last 24 hours\n",
    "temp = []\n",
    "fields = ['error%d' % i for i in range(1,6)]\n",
    "for col in fields:\n",
    "    temp.append(pd.pivot_table(error_count,    index='datetime',\n",
    "                                               columns='machineID',\n",
    "                                               values=col).rolling(window=24,center=False).sum().resample('3H',\n",
    "                                                                             closed='left',\n",
    "                                                                             label='right',\n",
    "                                                                             how='first').unstack())\n",
    "error_count = pd.concat(temp, axis=1)\n",
    "error_count.columns = [i + 'count' for i in fields]\n",
    "error_count.reset_index(inplace=True)\n",
    "error_count = error_count.dropna()\n",
    "\n",
    "print(error_count.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  machineID      comp1       comp2       comp3  \\\n",
      "0 2015-01-01 06:00:00          1  19.000000  214.000000  154.000000   \n",
      "1 2015-01-01 07:00:00          1  19.041667  214.041667  154.041667   \n",
      "2 2015-01-01 08:00:00          1  19.083333  214.083333  154.083333   \n",
      "3 2015-01-01 09:00:00          1  19.125000  214.125000  154.125000   \n",
      "4 2015-01-01 10:00:00          1  19.166667  214.166667  154.166667   \n",
      "\n",
      "        comp4  \n",
      "0  169.000000  \n",
      "1  169.041667  \n",
      "2  169.083333  \n",
      "3  169.125000  \n",
      "4  169.166667  \n"
     ]
    }
   ],
   "source": [
    "## Feature Engineering for maintenance\n",
    "\n",
    "#days since most recent component change\n",
    "# create a column for each error type\n",
    "comp_rep = pd.get_dummies(maint.set_index('datetime')).reset_index()\n",
    "comp_rep.columns = ['datetime', 'machineID', 'comp1', 'comp2', 'comp3', 'comp4']\n",
    "\n",
    "# combine repairs for a given machine in a given hour\n",
    "comp_rep = comp_rep.groupby(['machineID', 'datetime']).sum().reset_index()\n",
    "\n",
    "# add timepoints where no components were replaced\n",
    "comp_rep = telemetry[['datetime', 'machineID']].merge(comp_rep,\n",
    "                                                      on=['datetime', 'machineID'],\n",
    "                                                      how='outer').fillna(0).sort_values(by=['machineID', 'datetime'])\n",
    "\n",
    "components = ['comp1', 'comp2', 'comp3', 'comp4']\n",
    "for comp in components:\n",
    "    # convert indicator to most recent date of component change\n",
    "    comp_rep.loc[comp_rep[comp] < 1, comp] = None\n",
    "    comp_rep.loc[-comp_rep[comp].isnull(), comp] = comp_rep.loc[-comp_rep[comp].isnull(), 'datetime']\n",
    "\n",
    "    # forward-fill the most-recent date of component change\n",
    "    comp_rep[comp] = comp_rep[comp].fillna(method='ffill')\n",
    "\n",
    "# remove dates in 2014 (may have NaN or future component change dates)\n",
    "comp_rep = comp_rep.loc[comp_rep['datetime'] > pd.to_datetime('2015-01-01')]\n",
    "\n",
    "\n",
    "# replace dates of most recent component change with days since most recent component change\n",
    "for comp in components:\n",
    "    comp_rep[comp] = pd.Series(comp_rep[comp])\n",
    "    comp_rep[comp] = pd.to_datetime(comp_rep[comp])\n",
    "    comp_rep[comp] = (comp_rep['datetime'] - comp_rep[comp]) / np.timedelta64(1, 'D')\n",
    "\n",
    "print(comp_rep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all features\n",
    "final_feat = telemetry_feat.merge(error_count, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(comp_rep, on=['datetime', 'machineID'], how='left')\n",
    "final_feat = final_feat.merge(machines, on=['machineID'], how='left')\n",
    "\n",
    "print(final_feat.head())\n",
    "\n",
    "\n",
    "\n",
    "## Label construction\n",
    "labeled_features = final_feat.merge(failures, on=['datetime', 'machineID'], how='left')\n",
    "\n",
    "labeled_features['failure'] = labeled_features['failure'].fillna(method='bfill', limit=7) # fill backward up to 24h\n",
    "labeled_features['failure'] = labeled_features['failure'].fillna('none')\n",
    "labeled_features.head()\n",
    "print (labeled_features.head(1000))\n",
    "\n",
    "##\n",
    "export_final_feat_csv = final_feat.to_csv('final_feat.csv')\n",
    "export_labeled_features_csv = labeled_features.to_csv('labeled_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
